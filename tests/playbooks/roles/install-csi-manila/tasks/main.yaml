---
- name: Ensure CPO source folder is present
  shell:
    executable: /bin/bash
    cmd: |
      if [ ! -d "{{ ansible_user_dir }}/src/k8s.io/cloud-provider-openstack" ]; then
        echo "{{ ansible_user_dir }}/src/k8s.io/cloud-provider-openstack should exist but does not"
        exit 1
      fi

- name: Build and upload manila-csi-plugin image
  shell:
    executable: /bin/bash
    cmd: |
      cd {{ ansible_user_dir }}/src/k8s.io/cloud-provider-openstack
      VERSION="v0.0.99" # Fake version, but in proper format.

      make push-multiarch-image-manila-csi-plugin \
        ARCHS='amd64' \
        VERSION=${VERSION} \
        REGISTRY={{ image_registry_host }}

- name: Prepare cloud config
  shell:
    executable: /bin/bash
    cmd: |
      kubectl -n kube-system get secret cloud-config >/dev/null 2>&1
      if [ $? -eq 0 ]; then
        kubectl -n kube-system get secrets cloud-config -o json | jq -r '.data."cloud.conf"' | base64 -d
        # replacing a cloud-config, created by the OCCM role
        kubectl -n kube-system delete secret cloud-config
      fi

      set -ex

      set +x; source {{ devstack_workdir }}/openrc admin admin > /dev/null; set -x
      tenant_id=$(openstack project show demo -c id -f value)
      set +x; source {{ devstack_workdir }}/openrc demo demo > /dev/null; set -x
      cat <<EOF > {{ ansible_user_dir }}/cloud.conf
      [Global]
      auth-url=${OS_AUTH_URL}
      username=${OS_USERNAME}
      password=${OS_PASSWORD}
      region=${OS_REGION_NAME}
      tenant-id=$tenant_id
      domain-id=default

      [LoadBalancer]
      enabled=false
      EOF

      kubectl create secret -n kube-system generic cloud-config --from-file={{ ansible_user_dir }}/cloud.conf
      kubectl -n kube-system get secrets cloud-config -o json | jq -r '.data."cloud.conf"' | base64 -d

- name: Deploy Kubernetes VolumeSnapshot CRDs and snapshot controller
  shell:
    executable: /bin/bash
    cmd: |
      # TODO: Consider using kustomize once we move to external-snapshotter v5.
      for f in \
        'https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/release-4.2/client/config/crd/snapshot.storage.k8s.io_volumesnapshots.yaml' \
        'https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/release-4.2/client/config/crd/snapshot.storage.k8s.io_volumesnapshotcontents.yaml' \
        'https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/release-4.2/client/config/crd/snapshot.storage.k8s.io_volumesnapshotclasses.yaml' \
        'https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/release-4.2/deploy/kubernetes/snapshot-controller/rbac-snapshot-controller.yaml' \
        'https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/release-4.2/deploy/kubernetes/snapshot-controller/setup-snapshot-controller.yaml'
      do
        kubectl create -f "$f"
      done

- name: Deploy nfs-csi Node Plugin
  shell:
    executable: /bin/bash
    cmd: |
      cat <<EOF | kubectl create -f -
      kind: DaemonSet
      apiVersion: apps/v1
      metadata:
        name: csi-nodeplugin-nfsplugin
      spec:
        selector:
          matchLabels:
            app: csi-nodeplugin-nfsplugin
        template:
          metadata:
            labels:
              app: csi-nodeplugin-nfsplugin
          spec:
            containers:
              - name: nfs
                securityContext:
                  privileged: true
                  capabilities:
                    add: ["SYS_ADMIN"]
                  allowPrivilegeEscalation: true
                image: quay.io/k8scsi/nfsplugin:v2.0.0
                args:
                  - "--nodeid=\$(NODE_ID)"
                  - "--endpoint=unix://plugin/csi.sock"
                env:
                  - name: NODE_ID
                    valueFrom:
                      fieldRef:
                        fieldPath: spec.nodeName
                imagePullPolicy: IfNotPresent
                volumeMounts:
                  - name: plugin-dir
                    mountPath: /plugin
                  - name: pods-mount-dir
                    mountPath: /var/lib/kubelet/pods
                    mountPropagation: Bidirectional
            volumes:
              - name: plugin-dir
                hostPath:
                  path: /var/lib/kubelet/plugins/csi-nfsplugin
                  type: DirectoryOrCreate
              - name: pods-mount-dir
                hostPath:
                  path: /var/lib/kubelet/pods
                  type: Directory
      EOF

- name: Deploy manila-csi-plugin
  shell:
    executable: /bin/bash
    cmd: |
      VERSION="v0.0.99" # Fake version, but in proper format.
      cd {{ ansible_user_dir }}/src/k8s.io/cloud-provider-openstack/charts/manila-csi-plugin
      cat <<EOF >> override-helm-values.yaml
      csimanila:
        image:
          repository: {{ remote_registry_host }}/manila-csi-plugin
          tag: ${VERSION}
      shareProtocols:
        - protocolSelector: NFS
          fsGroupPolicy: None
          fwdNodePluginEndpoint:
            dir: /var/lib/kubelet/plugins/csi-nfsplugin
            sockFile: csi.sock
      EOF

      helm install shares . -f override-helm-values.yaml

- name: Wait for manila-csi-plugin controller plugin up and running
  shell:
    executable: /bin/bash
    cmd: |
      kubectl get pod -l app=openstack-manila-csi,component=controllerplugin | grep Running
  register: check_csi_controller
  until: check_csi_controller.rc == 0
  retries: 24
  delay: 5
  ignore_errors: true

- name: Wait for manila-csi-plugin node plugin up and running
  shell:
    executable: /bin/bash
    cmd: |
      kubectl get pod -l app=openstack-manila-csi,component=nodeplugin | grep Running
  register: check_csi_node
  until: check_csi_node.rc == 0
  retries: 24
  delay: 5
  ignore_errors: true

- name: Gather additional evidence if csi-manila-plugin failed to come up
  when: check_csi_controller.failed or check_csi_node.failed
  block:
    - name: Describe failed manila-csi-plugin
      shell:
        executable: /bin/bash
        cmd: |
          kubectl get pods -A
          kubectl describe statefulset -l app=openstack-manila-csi,component=controllerplugin
          kubectl describe daemonset -l app=openstack-manila-csi,component=nodeplugin
          kubectl describe pod -l app=openstack-manila-csi,component=controllerplugin
          kubectl describe pod -l app=openstack-manila-csi,component=nodeplugin
      register: describe_csi
      changed_when: false

    - name: Show openstack-cloud-controller-manager pod logs
      shell:
        executable: /bin/bash
        cmd: |
          kubectl -n kube-system logs ds/openstack-cloud-controller-manager

    - name: Log failed manila-csi-plugin deployment
      debug:
        var: describe_csi.stdout_lines

    - name: &failmsg Stop due to prior failure of manila-csi-plugin
      fail:
        msg: *failmsg

- name: Prepare devstack secrets
  shell:
    executable: /bin/bash
    cmd: |
      set +x; source {{ devstack_workdir }}/openrc demo demo > /dev/null; set -x

      cat <<EOF | kubectl create -f -
      apiVersion: v1
      kind: Secret
      metadata:
        name: csi-manila-secrets
        namespace: default
      # Use the devstack ``demo`` user in the ``demo`` project rather than ``admin``
      # since regular users should be able to use the cloud-provider-openstack
      # APIs without OpenStack administrative privileges.  Devstack sets up
      # up the same password for both users.
      stringData:
        os-authURL: "$OS_AUTH_URL"
        os-region: "$OS_REGION_NAME"
        os-userName: "demo"
        os-password: "$OS_PASSWORD"
        os-projectName: "demo"
        os-domainID: "$OS_USER_DOMAIN_ID"
      EOF

- name: Run functional tests for manila-csi-plugin
  shell:
    executable: /bin/bash
    cmd: |
      set -x
      set -e
      set -o pipefail

      set +x; source {{ devstack_workdir }}/openrc demo demo > /dev/null; set -x

      cd {{ ansible_user_dir }}/src/k8s.io/cloud-provider-openstack
      mkdir -p /var/log/csi-pod
      # GATEWAY_IP is the default value in devstack
      GATEWAY_IP=172.24.5.1 \
      OS_RC={{ devstack_workdir }}/openrc \
      go test -v ./cmd/tests/manila-csi-e2e-suite/manila_csi_e2e_suite_test.go \
        --ginkgo.focus="\[manila-csi-e2e\]" \
        --ginkgo.skip="\[Disruptive\]|\[sig-storage\]\s+\[manila-csi-e2e\]\s+CSI\s+Volumes\s+\[Driver:\s+nfs.manila.csi.openstack.org\]\s+\[Testpattern:\s+Dynamic\s+PV\s+\(default\s+fs\)\]\s+provisioning\s+should\s+provision\s+storage\s+with\s+any\s+volume\s+data\s+source\s+\[Serial\]|should\s+provision\s+storage\s+with\s+snapshot\s+data\s+source|restoring\s+snapshot\s+to\s+larger\s+size" \
        --ginkgo.v \
        --ginkgo.no-color \
        --ginkgo.show-node-events \
        --ginkgo.timeout=1h45m \
        -timeout=0 \
        -report-dir /var/log/csi-pod | tee "/var/log/csi-pod/manila-csi-e2e.log"
  register: functional_test_result
  ignore_errors: true
  async: 6600 # wait 1h50m (i.e. 5 mins longer than the ginkgo timeout) then fail and fetch the logs
  poll: 15

- name: Collect pod logs for debug purpose
  shell:
    executable: /bin/bash
    cmd: |
      set -x
      set -e

      kubectl logs -l app=openstack-manila-csi,component=controllerplugin -n default -c nfs-nodeplugin --tail=-1 > /var/log/csi-pod/csi-manila-controllerplugin.log
      kubectl logs -l app=openstack-manila-csi,component=nodeplugin -n default -c nfs-nodeplugin --tail=-1 > /var/log/csi-pod/csi-manila-nodeplugin.log
  ignore_errors: true

- fail: msg="The execution has failed because of errors."
  when: functional_test_result.failed
